{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Troubleshooting\n",
    "\n",
    "This Jupyter Notebook runs regressions for MOSAIKS features with PCA applied. \n",
    "\n",
    "Right now, this notebook only runs such regressions for the \"population\" label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "from mosaiks.code.mosaiks import config as cfg\n",
    "from mosaiks.code.mosaiks.utils import io\n",
    "from mosaiks.code.mosaiks.solve import data_parser as parse\n",
    "from mosaiks.code.mosaiks.solve import solve_functions as solve\n",
    "from mosaiks.code.mosaiks.solve import interpret_results as ir\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "This notebook is only running regressions for the label \"population\" for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run for MOSAIKS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, latlons= io.get_X_latlon(cfg, \"UAR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run for TorchGeo RCF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/int/feature_matrices/CONTUS_UAR_torchgeo.pkl\", \"rb\") as f:\n",
    "        arrs = dill.load(f)\n",
    "X = pd.DataFrame(\n",
    "    arrs[\"X\"].astype(np.float64),\n",
    "    index=arrs[\"ids_X\"],\n",
    "    columns=[\"X_\" + str(i) for i in range(arrs[\"X\"].shape[1])],\n",
    ")\n",
    "\n",
    "# get latlons\n",
    "latlons = pd.DataFrame(arrs[\"latlon\"], index=arrs[\"ids_X\"], columns=[\"lat\", \"lon\"])\n",
    "\n",
    "# sort both\n",
    "latlons = latlons.sort_values([\"lat\", \"lon\"], ascending=[False, True])\n",
    "X = X.reindex(latlons.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"population\"\n",
    "\n",
    "solver = solve.ridge_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test all lambdas (specified in config file)\n",
    "this_lambdas = io.get_lambdas(cfg, label, best_lambda_fpath=None)\n",
    "\n",
    "c = io.get_filepaths(cfg, label)\n",
    "c_app = getattr(c, label)\n",
    "\n",
    "#Bounds from config file\n",
    "if c_app[\"logged\"]:\n",
    "    bounds = np.array([c_app[\"us_bounds_log_pred\"]])\n",
    "else:\n",
    "    bounds = np.array([c_app[\"us_bounds_pred\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    this_X,\n",
    "    this_X_test,\n",
    "    this_Y,\n",
    "    this_Y_test,\n",
    "    this_latlons,\n",
    "    this_latlons_test,\n",
    "    this_emb,\n",
    "    this_emb_test\n",
    ") = parse.merge_dropna_transform_split_train_test(\n",
    "    c, label, X, latlons, None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove training points so size of train set is divisible by 5 (for Cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(this_X)\n",
    "this_X = this_X[:-(n%5)]\n",
    "this_Y = this_Y[:-(n%5)]\n",
    "this_latlons = this_latlons[:-(n%5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "1) Combine Train and Test (``this_X``, ``this_X_test``)\n",
    "2) Initialize PCA (PCA(0.99) retaines 99% of the variance; can also specify PCA(num_components = 13) or other desired number)\n",
    "3) ``fit_transform`` to combined data\n",
    "4) Split data into train and test\n",
    "\n",
    "PCA is done at this step since when X is initially retrieved as a data frame, some values are NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First combine train and test so PCA can be applied to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((this_X, this_X_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the next block to scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = StandardScaler()\n",
    "scaling.fit(X)\n",
    "X = scaling.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform PCA (to modify number of components, change PCA(n_components) to be either specified number of components or % retained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "print(\"Performing PCA...\")\n",
    "pca = PCA(0.99)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(\"Number of PCA Components: \", pca.n_components_)\n",
    "\n",
    "#Separate train and test\n",
    "this_X = X_pca[:this_X.shape[0], :]\n",
    "this_X_test = X_pca[this_X.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check\n",
    "\n",
    "Number of test samples: 13585\n",
    "\n",
    "1) For \"population\", number of train samples is 54343 (this is reduced to 54340 for 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54340, 8192)\n",
      "(13585, 8192)\n"
     ]
    }
   ],
   "source": [
    "print(this_X.shape)\n",
    "print(this_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Regressions\n",
    "\n",
    "Code from MOSAIKS run_regressions.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Running regressions for: population\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 \n",
      "Training time: 95.62686777114868\n",
      "Test set training time: 17.239691972732544\n",
      "R^2 score:  0.7413341635475623\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Running regressions for: {label}\".format(label=label))\n",
    "\n",
    "print(\"Training model...\")\n",
    "import time\n",
    "\n",
    "st_train = time.time()\n",
    "kfold_results = solve.kfold_solve(\n",
    "    this_X,\n",
    "    this_Y,\n",
    "    solve_function=solver,\n",
    "    num_folds=c.ml_model[\"n_folds\"],\n",
    "    return_model=True,\n",
    "    lambdas=this_lambdas,\n",
    "    return_preds=True,\n",
    "    svd_solve=False,\n",
    "    clip_bounds=bounds,\n",
    ")\n",
    "print(\"\")\n",
    "\n",
    "# get timing\n",
    "training_time = time.time() - st_train\n",
    "print(\"Training time:\", training_time)\n",
    "\n",
    "## Store the metrics and the predictions from the best performing model\n",
    "best_lambda_idx, best_metrics, best_preds = ir.interpret_kfold_results(\n",
    "    kfold_results, \"r2_score\", hps=[(\"lambdas\", c_app[\"lambdas\"])]\n",
    ")\n",
    "best_lambda = this_lambdas[best_lambda_idx][0]\n",
    "\n",
    "# Get test set predictions\n",
    "st_test = time.time()\n",
    "holdout_results = solve.single_solve(\n",
    "    this_X,\n",
    "    this_X_test,\n",
    "    this_Y,\n",
    "    this_Y_test,\n",
    "    lambdas=best_lambda,\n",
    "    svd_solve=False,\n",
    "    return_preds=True,\n",
    "    return_model=False,\n",
    "    clip_bounds=bounds,\n",
    ")\n",
    "\n",
    "#Get timing\n",
    "test_time = time.time() - st_test\n",
    "print(\"Test set training time:\", test_time)\n",
    "\n",
    "print(\"R^2 score: \", holdout_results[\"metrics_test\"][0][0][0][\"r2_score\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiksenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
