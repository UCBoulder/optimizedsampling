{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Troubleshooting\n",
    "\n",
    "This Jupyter Notebook runs regressions for MOSAIKS features with PCA applied. \n",
    "\n",
    "Right now, this notebook only runs such regressions for the \"population\" label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env variable MOSAIKS_HOME not defined; setting to: \"/home/libe2152/optimizedsampling\"\n",
      "If not desired, please reset os.environ[\"MOSAIKS_NAME\"]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dill\n",
    "import numpy as np\n",
    "\n",
    "from mosaiks.code.mosaiks import config as cfg\n",
    "from mosaiks.code.mosaiks.utils import io\n",
    "from mosaiks.code.mosaiks.solve import data_parser as parse\n",
    "from mosaiks.code.mosaiks.solve import solve_functions as solve\n",
    "from mosaiks.code.mosaiks.solve import interpret_results as ir\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "This notebook is only running regressions for the label \"population\" for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run for MOSAIKS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, latlons= io.get_X_latlon(cfg, \"UAR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run for TorchGeo RCF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/int/feature_matrices/CONTUS_UAR_torchgeo.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/int/feature_matrices/CONTUS_UAR_torchgeo.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m         arrs \u001b[38;5;241m=\u001b[39m dill\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      3\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m      4\u001b[0m     arrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m      5\u001b[0m     index\u001b[38;5;241m=\u001b[39marrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids_X\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      6\u001b[0m     columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(arrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])],\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m/share/anaconda3/envs/sampling/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/int/feature_matrices/CONTUS_UAR_torchgeo.pkl'"
     ]
    }
   ],
   "source": [
    "with open(\"data/int/feature_matrices/CONTUS_UAR_torchgeo.pkl\", \"rb\") as f:\n",
    "        arrs = dill.load(f)\n",
    "X = pd.DataFrame(\n",
    "    arrs[\"X\"].astype(np.float64),\n",
    "    index=arrs[\"ids_X\"],\n",
    "    columns=[\"X_\" + str(i) for i in range(arrs[\"X\"].shape[1])],\n",
    ")\n",
    "\n",
    "# get latlons\n",
    "latlons = pd.DataFrame(arrs[\"latlon\"], index=arrs[\"ids_X\"], columns=[\"lat\", \"lon\"])\n",
    "\n",
    "# sort both\n",
    "latlons = latlons.sort_values([\"lat\", \"lon\"], ascending=[False, True])\n",
    "X = X.reindex(latlons.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"population\"\n",
    "\n",
    "solver = solve.ridge_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test all lambdas (specified in config file)\n",
    "this_lambdas = io.get_lambdas(cfg, label, best_lambda_fpath=None)\n",
    "\n",
    "c = io.get_filepaths(cfg, label)\n",
    "c_app = getattr(c, label)\n",
    "\n",
    "#Bounds from config file\n",
    "if c_app[\"logged\"]:\n",
    "    bounds = np.array([c_app[\"us_bounds_log_pred\"]])\n",
    "else:\n",
    "    bounds = np.array([c_app[\"us_bounds_pred\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labels...\n",
      "Merging labels and features...\n",
      "Splitting training/test...\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    this_X,\n",
    "    this_X_test,\n",
    "    this_Y,\n",
    "    this_Y_test,\n",
    "    this_latlons,\n",
    "    this_latlons_test,\n",
    "    this_emb,\n",
    "    this_emb_test\n",
    ") = parse.merge_dropna_transform_split_train_test(\n",
    "    c, label, X, latlons, None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove training points so size of train set is divisible by 5 (for Cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(this_X)\n",
    "this_X = this_X[:-(n%5)]\n",
    "this_Y = this_Y[:-(n%5)]\n",
    "this_latlons = this_latlons[:-(n%5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "1) Combine Train and Test (``this_X``, ``this_X_test``)\n",
    "2) Initialize PCA (PCA(0.99) retaines 99% of the variance; can also specify PCA(num_components = 13) or other desired number)\n",
    "3) ``fit_transform`` to combined data\n",
    "4) Split data into train and test\n",
    "\n",
    "PCA is done at this step since when X is initially retrieved as a data frame, some values are NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First combine train and test so PCA can be applied to all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((this_X, this_X_test), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the next block to scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = StandardScaler()\n",
    "scaling.fit(X)\n",
    "X = scaling.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform PCA (to modify number of components, change PCA(n_components) to be either specified number of components or % retained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing PCA...\n",
      "Number of PCA Components:  17\n"
     ]
    }
   ],
   "source": [
    "#PCA\n",
    "print(\"Performing PCA...\")\n",
    "pca = PCA(0.99)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "print(\"Number of PCA Components: \", pca.n_components_)\n",
    "\n",
    "#Separate train and test\n",
    "this_X = X_pca[:this_X.shape[0], :]\n",
    "this_X_test = X_pca[this_X.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check\n",
    "\n",
    "Number of test samples: 13585\n",
    "\n",
    "1) For \"population\", number of train samples is 54343 (this is reduced to 54340 for 5-fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54340, 17)\n",
      "(13585, 17)\n"
     ]
    }
   ],
   "source": [
    "print(this_X.shape)\n",
    "print(this_X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Regressions\n",
    "\n",
    "Code from MOSAIKS run_regressions.ipynb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Running regressions for: population\n",
      "Training model...\n",
      "on fold (of 5): 1 2 3 4 5 \n",
      "Training time: 0.08356571197509766\n",
      "Test set training time: 0.0120391845703125\n",
      "Cross Validation R^2 score:  -0.09621940222801761\n",
      "R^2 score:  -0.1178933905337729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/libe2152/optimizedsampling/mosaiks/code/mosaiks/solve/interpret_results.py:69: UserWarning: Only one value for hyperparameter number 0 supplied.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Running regressions for: {label}\".format(label=label))\n",
    "\n",
    "print(\"Training model...\")\n",
    "import time\n",
    "\n",
    "st_train = time.time()\n",
    "kfold_results = solve.kfold_solve(\n",
    "    this_X,\n",
    "    this_Y,\n",
    "    solve_function=solver,\n",
    "    num_folds=c.ml_model[\"n_folds\"],\n",
    "    return_model=True,\n",
    "    lambdas=[1e-8],\n",
    "    return_preds=True,\n",
    "    svd_solve=False,\n",
    "    clip_bounds=bounds,\n",
    "    intercept=True,\n",
    ")\n",
    "print(\"\")\n",
    "\n",
    "# get timing\n",
    "training_time = time.time() - st_train\n",
    "print(\"Training time:\", training_time)\n",
    "\n",
    "## Store the metrics and the predictions from the best performing model\n",
    "best_lambda_idx, best_metrics, best_preds = ir.interpret_kfold_results(\n",
    "    kfold_results, \"r2_score\", hps=[(\"lambdas\", c_app[\"lambdas\"])]\n",
    ")\n",
    "best_lambda = this_lambdas[best_lambda_idx][0]\n",
    "\n",
    "# Get test set predictions\n",
    "st_test = time.time()\n",
    "holdout_results = solve.single_solve(\n",
    "    this_X,\n",
    "    this_X_test,\n",
    "    this_Y,\n",
    "    this_Y_test,\n",
    "    lambdas=[1e-8],\n",
    "    svd_solve=False,\n",
    "    return_preds=True,\n",
    "    return_model=False,\n",
    "    clip_bounds=bounds,\n",
    "    intercept=True\n",
    ")\n",
    "\n",
    "#Get timing\n",
    "test_time = time.time() - st_test\n",
    "print(\"Test set training time:\", test_time)\n",
    "\n",
    "print(\"Cross Validation R^2 score: \", kfold_results[\"metrics_test\"][0][0][0][\"r2_score\"])\n",
    "\n",
    "print(\"R^2 score: \", holdout_results[\"metrics_test\"][0][0][0][\"r2_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Ridge regression with all features (no crossval to pick alpha)\n",
    "import sklearn\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "solve() got an unexpected keyword argument 'sym_pos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m reg \u001b[38;5;241m=\u001b[39m Ridge(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mreg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43mthis_Y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m yhat_test \u001b[38;5;241m=\u001b[39m reg\u001b[38;5;241m.\u001b[39mpredict(this_X_test)\n\u001b[1;32m      6\u001b[0m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mr2_score(this_Y_test, yhat_test)\n",
      "File \u001b[0;32m/share/anaconda3/envs/sampling/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:762\u001b[0m, in \u001b[0;36mRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    744\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Ridge regression model.\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    self : returns an instance of self.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/share/anaconda3/envs/sampling/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:593\u001b[0m, in \u001b[0;36m_BaseRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;66;03m# for dense matrices or when intercept is set to 0\u001b[39;00m\n\u001b[1;32m    591\u001b[0m         params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_ridge_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_intercept(X_offset, y_offset, X_scale)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/share/anaconda3/envs/sampling/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:471\u001b[0m, in \u001b[0;36m_ridge_regression\u001b[0;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 471\u001b[0m         coef \u001b[38;5;241m=\u001b[39m \u001b[43m_solve_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;66;03m# use SVD solver if matrix is singular\u001b[39;00m\n\u001b[1;32m    474\u001b[0m         solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/share/anaconda3/envs/sampling/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:147\u001b[0m, in \u001b[0;36m_solve_cholesky\u001b[0;34m(X, y, alpha)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m one_alpha:\n\u001b[1;32m    146\u001b[0m     A\u001b[38;5;241m.\u001b[39mflat[::n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m alpha[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msym_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m     coefs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty([n_targets, n_features], dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: solve() got an unexpected keyword argument 'sym_pos'"
     ]
    }
   ],
   "source": [
    "reg = Ridge(alpha=1e-8)\n",
    "reg.fit(this_X,this_Y)\n",
    "\n",
    "yhat_test = reg.predict(this_X_test)\n",
    "\n",
    "sklearn.metrics.r2_score(this_Y_test, yhat_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mosaiksenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
